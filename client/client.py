import asyncio
import streamlit as st
from dotenv import load_dotenv
from agents import Agent, Runner
from agents.mcp import MCPServerStreamableHttp

load_dotenv()

# ----------------------------------------------------------------------
# ğŸŒ ConexÃ£o com o servidor MCP
# ----------------------------------------------------------------------
mcp_server = MCPServerStreamableHttp({"url": "http://localhost:8000/mcp"})

# ----------------------------------------------------------------------
# ğŸ¤– DefiniÃ§Ã£o do agente
# ----------------------------------------------------------------------

agente_compras = Agent(
    name="AssistenteCompras",
    instructions="""
        VocÃª Ã© um assistente de compras **exclusivamente** responsÃ¡vel por
        listar fornecedores que atendem a um material dentro de uma categoria.
        VocÃª tem que identificar qual categoria e material baseado na informaÃ§Ã£o
        retornadas pelas tools 'list_categories' e 'list_materials'. 
        
        Use a ferramenta mais adequada com base na intenÃ§Ã£o do usuÃ¡rio.
        â€¢ Use 'list_categories' para saber as categorias disponÃ­veis.
        â€¢ Use 'list_materials' para saber os materiais disponÃ­veis.
        â€¢ Use'list_suppliers' para listar os fornecedores de um material
          dentro de uma categoria.
        â€¢ NÃ£o forneÃ§a informaÃ§Ãµes adicionais, apenas a lista de fornecedores.
        â€¢ Se o usuÃ¡rio nÃ£o fornecer a categoria ou o material, solicite essas informaÃ§Ãµes.

        Adicione na resposta uma linha mostrando o fluxo de ferramentas utilizadas e
        quais argumentos usados em cada uma.
    """,
    model="gpt-4o-mini",
    mcp_servers=[mcp_server],
)

# ----------------------------------------------------------------------
# ğŸ”„ FunÃ§Ã£o assÃ­ncrona para perguntar ao agente
# ----------------------------------------------------------------------
async def ask_agent(question: str) -> str:
    await mcp_server.connect()
    result = await Runner.run(agente_compras, question)
    return result.final_output

# ----------------------------------------------------------------------
# ğŸ¨ Interface Streamlit
# ----------------------------------------------------------------------

st.title("Assistente de Compras - Chat")
st.markdown("Converse com o assistente para criar solicitaÃ§Ãµes de compra e gerenciar propostas.")

# Estado da conversa armazenado na sessÃ£o (histÃ³rico de mensagens)
if "history" not in st.session_state:
    st.session_state.history = []  # lista de (role, message)

# Caixa de entrada do usuÃ¡rio
entrada = st.chat_input("Digite sua mensagem:")
if entrada:
    # Exibe imediatamente a mensagem do usuÃ¡rio na interface
    st.session_state.history.append(("user", entrada))
    # Chama o agente da OpenAI para obter a resposta
    resultado = asyncio.run(ask_agent(entrada))  # executa a funÃ§Ã£o assÃ­ncrona    
    # Armazena e exibe a resposta do assistente
    st.session_state.history.append(("assistant", resultado))

# Renderiza o histÃ³rico de mensagens na tela
for role, msg in st.session_state.history:
    with st.chat_message(role):
        st.write(msg)